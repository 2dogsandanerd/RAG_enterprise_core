# RAG Enterprise Core

Enterprise-grade Retrieval-Augmented Generation system with microservices architecture.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-brightgreen.svg)](https://www.docker.com/)

## ğŸ¯ Features

- ğŸ¤– **LangGraph Orchestration** - Intelligent query routing and agentic workflows
- ğŸ—„ï¸ **ChromaDB Vector Store** - Persistent semantic search
- ğŸ“„ **Docling Integration** - High-quality PDF processing
- ğŸ’¬ **Conversation Memory** - Redis-based session management
- ğŸ”„ **Resilience Patterns** - Retry, circuit breaker, rate limiting
- ğŸ“Š **Full Observability** - Prometheus + Grafana monitoring
- ğŸ³ **Docker Ready** - Complete containerized deployment

## ğŸ“‹ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent     â”‚ â† LangGraph Orchestration + Redis Memory
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚  Knowledge  â”‚   â”‚  Ingest   â”‚
â”‚  (ChromaDB) â”‚   â”‚ (Docling) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**[Full Architecture Documentation â†’](docs/architecture.md)**

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Ollama

### 1. Setup

```bash
cd /mnt/dev/eingang/rag_enterprise_core
cp .env.example .env
# No API keys needed - uses Ollama by default
# (Only edit .env if you want to use OpenAI instead)
```

### 2. Start All Services

```bash
docker-compose up -d
```

### 3. Verify Health

```bash
curl http://localhost:8003/health  # Agent
curl http://localhost:8002/health  # Knowledge
curl http://localhost:8001/health  # Ingest
```

### 4. Test Chat

```bash
curl -X POST http://localhost:8003/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "Hello, how are you?"}'
```

## ğŸ“š Services

| Service 		| Port | Description 				| Docs 										|
|---------------|------|----------------------------|-------------------------------------------|
| **Agent** 	| 8003 | LangGraph orchestration	| [README](services/agent/README.md) 		|
| **Knowledge** | 8002 | ChromaDB vector search 	| [README](services/knowledge/README.md) 	|
| **Ingest** 	| 8001 | Docling document processing| [README](services/ingest/README.md) 		|
| **Redis** 	| 6379 | Conversation memory 		| - 										|
| **Prometheus**| 9090 | Metrics collection 		| - 										|
| **Grafana** 	| 3000 | Dashboards 				| - 										|


## ğŸ“– API Documentation

Once services are running:

- **Agent API:** http://localhost:8003/docs
- **Knowledge API:** http://localhost:8002/docs
- **Ingest API:** http://localhost:8001/docs


## ğŸ”§ Configuration

### Environment Variables

```bash
# All settings are optional - Ollama is used by default
# No API keys required for default setup

# Optional: Use OpenAI instead of Ollama
# OPENAI_API_KEY=your_openai_api_key
# LLM_PROVIDER=openai

# Service URLs (defaults shown)
KNOWLEDGE_SERVICE_URL=http://knowledge:8000
REDIS_URL=redis://redis:6379
```

## ğŸ’» Development

### Install Service

```bash
cd services/agent  # or knowledge, ingest
pip install -e .
```

### Run Service Locally

```bash
uvicorn rag_enterprise_agent.service:app --reload --port 8003
```

### Run Tests

```bash
pytest tests/ -v --cov
```

## ğŸ“Š Monitoring

- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **Metrics**: http://localhost:8003/metrics

## ğŸ›¡ï¸ Resilience Features

- âœ… **Retry Logic** 		- Exponential backoff (3 attempts)
- âœ… **Circuit Breaker** 	- Fail-fast after 5 failures
- âœ… **Rate Limiting** 		- 10 req/min per IP (Agent)
- âœ… **Graceful Shutdown** 	- Clean connection closure
- âœ… **Health Checks** 		- Docker health probes

## ğŸ§ª Testing

```bash
# Unit tests
pytest services/agent/tests/unit -v

# Integration tests
pytest tests/integration -v

# Coverage report
pytest --cov --cov-report=html
```

## ğŸ“¦ Project Structure

```
rag_enterprise_core/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ agent/          # LangGraph orchestration
â”‚   â”œâ”€â”€ knowledge/      # ChromaDB vector store
â”‚   â””â”€â”€ ingest/         # Docling processing
â”œâ”€â”€ shared/             # Shared models & utilities
â”œâ”€â”€ infrastructure/     # Prometheus & Grafana configs
â”œâ”€â”€ docs/               # Documentation
â”œâ”€â”€ tests/              # Integration tests
â””â”€â”€ docker-compose.yml
```

## ğŸ”„ Workflow

### 1. Ingest Documents

```bash
curl -X POST http://localhost:8001/ingest \
  -F "file=@document.pdf" \
  -F "collection_name=my_docs"
```

### 2. Chat with RAG

```bash
curl -X POST http://localhost:8003/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is in the document?",
    "session_id": "optional-uuid"
  }'
```

### 3. View Session History

```bash
curl http://localhost:8003/sessions/{session_id}
```

## ğŸ“ Documentation

- [Architecture](docs/architecture.md) 				- System design and diagrams
- [Agent Service](services/agent/README.md) 		- LangGraph orchestration
- [Knowledge Service](services/knowledge/README.md) - Vector search
- [Ingest Service](services/ingest/README.md) 		- Document processing

## ğŸš§ Roadmap
-
